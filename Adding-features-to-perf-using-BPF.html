<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Adding features to perf using BPF</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h2>Adding features to perf using BPF</h2>
					<br>
					<br>
					<table>
						<tbody>
							<tr>
								<th>
									<i>Arnaldo Carvalho de Melo</i>
									<br>
									<i>acme@redhat.com</i>
								</th>
							</tr>
							<tr>
								<th>
									<i>Song Liu</i>
									<br>
									<i>song@kernel.org</i>
								</th>
							</tr>
							<tr>
								<th>
									<i>Namhyung Kim</i>
									<br>
									<i>namhyung@kernel.org</i>
								</th>
							</tr>
						</tbody>
					</table>
				</section>
				<section>
					<h2>What is this about?</h2>
					<br>
					<br>
					<ul>
						<li>perf tools: familiar control plane</li>
						<li>BPF: flexible, powerful dataplane</li>
						<li>BTF for pretty printing and more</li>
					</ul>
				</section>
				<section>
					<h2>perf for BPF</h2>
					<br>
					<br>
					<ul>
						<li>BPF profiling</li>
						<li>BPF sampling</li>
						<li>BPF annotation</li>
						<li>BPF event counting</li>
					</ul>
				</section>
				<section>
					<h2>BPF for perf</h2>
					<br>
					<br>
					<ul>
						<li>BPF event counting</li>
						<li>perf using BPF to count events in BPF code</li>
						<li>bpftool prog profile</li>
						<li>perf stat -b/--bpf-prog PROG_ID</li>
						<li>perf stat --bpf-counters</li>
						<li>perf stat --bpf-counters --for-each-cgroup</li>
					</ul>
				</section>
				<section>
					<h2>BPF for perf</h2>
					<br>
					<br>
					<ul>
						<li>Reuse BPF infrastructure in perf</li>
						<li>build-ids</li>
						<li>bpf_get_stack(BPF_F_USER_BUILD_ID)</li>
						<li>Use in PERF_RECORD_MMAP2</li>
					</ul>
				</section>
				<section>
					<h2>bpfprog profile</h2>
					<br>
					<br>
					<ul>
						<li>Limited to some events</li>
						<li>cycles, instructions, l1d_loads, llc_misses</li>
						<li>itlb_misses and dtlb_misses</li>
						<li>Different workflow from familiar 'perf stat'</li>
						<li>New tool, few features</li>
					</ul>
				</section>
				<section>
					<h4>bpftool prog profile help</h4>
					<br>
					<pre>
$ bpftool prog help
       bpftool prog profile PROG [duration DURATION] METRICs

       PROG := { id PROG_ID | pinned FILE | tag PROG_TAG | name PROG_NAME }
       METRIC := { cycles | instructions | l1d_loads | llc_misses | itlb_misses | dtlb_misses }
$
					</pre>
				</section>
				<section>
					<h4>bpftool prog profile</h4>
					<br>
					<pre>
$ bpftool prog profile id 324 duration 3 cycles itlb_misses

       1885029 run_cnt
    5134686073 cycles
        306893 itlb_misses
					</pre>
				</section>
				<section>
					<h2>perf stat for BPF</h2>
					<br>
					<br>
					<ul>
						<li>Just another target</li>
						<li>pid, tid, cpu, cgroup, BPF_PROG</li>
						<li>Familiar workflow</li>
						<li>Lots of events</li>
						<li>Metrics</li>
						<li>First class perf stat citizen</li>
					</ul>
				</section>
				<section>
					<h2>But how? BPF skels</h2>
					<br>
					<br>
					<ul>
						<li>Canonical example: tools/bpf/runqslower</li>
						<li>Lots of boilerplate taken care of</li>
						<li>BPF built and "linked" with perf</li>
						<li>Details on <a href=http://vger.kernel.org/~acme/bpf/devconf.cz-2020-BPF-The-Status-of-BTF-producers-consumers/#/40>Devconf.cz 2020 BPF talk</a></li>
					</ul>
				</section>
				<section>
					<h4>Using it</h4>
					<br>
					<pre>
# perf stat -e ref-cycles,cycles --bpf-prog 254 --interval-print 1000
    1.487903822            115,200      ref-cycles
    1.487903822             86,012      cycles
    2.489147029             80,560      ref-cycles
    2.489147029             73,784      cycles
    3.490341825             60,720      ref-cycles
    3.490341825             37,797      cycles
#
# # Equivalent to:
#
# perf stat -e ref-cycles,cycles -b 254 -I 1000

					</pre>
				</section>
				<section>
					<h2>perf stat BPF counters</h2>
					<br>
					<br>
					<ul>
						<li>FILL IN</li>
						<li>ADD SLIDE SHOWING IT IN ACTION</li>
						<li>TO SHOW ITS ADVANTAGES OVER PERF STAT</li>
					</ul>
				</section>
				<section>
					<h2> bperf: perf stat with BPF backend </h2>
				</section>
				<section>
					<h3> bperf: the problem </h3>
					<ul>
						<li> Mutliple tools monitor same common metrics (cycles, instrcutions) at different granularities: system wide, per process, per request, etc. </li>
						<li> Limited hardware counters</li>
						<li> Time multiplexing when there are more active events than hardware counters: low accuracy or high overhead </li>
						<li> Sharing counters in kernel is hard. After <a href=https://lkml.org/lkml/2020/5/1/1418> v13 of this patchset </a>, I started hating it myself. </li>
					</ul>
				</section>				
				<section>
					<h3> bperf: the solution </h3>
					<ul>
						<li> Use BPF to manage hardware hardware counters</li>
						<li> Create per cpu perf events on each cpu </li>
						<li> BPF program triggers on the context switch, reads perf events, and aggregates reading in BPF maps.</li>
						<li> User space reads output from BPF maps. </li>
					</ul>
				</section>
				<section>
					<h3> bperf: architecture </h3>
                                        <img src="img/bperf-arch.png">
				</section>
				<section>
					<h3> bperf: share across processes </h3>
					<ul>
						<li> BPF hashmap pinned in <code>/sys/fs/bpf/perf_attr_map</code></li>
						<li> Each user holds a fd to the bpf_link </li>
						<li> The perf_events, BPF programs, maps are freed when the last user exits (or closes all fds)</li>
					</ul>
					<pre data-id="code-animation"><code class="hljs" data-trim data-line-numbers>
						struct perf_event_attr_map_entry {
							__u32 link_id;   /* bpf_link of the leader prog */
							__u32 diff_map_id;
						};
					</code></pre>
				</section>
				<section>
					<h3> bperf: share across processes </h3>
					<ul>
						<li> Monitor daemons and self monitoring processes may share hardware counters with perf-stat</li>
						<li> Kernel supports up to 38 (BPF_MAX_TRAMP_PROGS) follower progs per leader prog </li>
						<li> Share one set of hardware counters (one per cpu) among up to 38 different processes </li>
					</ul>
				</section>
				<section>
					<h2>perf stat cgroup Usecase</h2>
					<br>
					<br>
					<ul>
						<li>Google runs hundreds of jobs on a single machine</li>
						<li>any workload runs inside a cgroup</li>
						<li>wants to monitor each job (counting mode)</li>
						<li>reference: <a href="https://www.linuxplumbersconf.org/event/4/contributions/291/">LPC 2019 talk</a></li>
					</ul>
				</section>				
				<section>
					<h2>Scalability issues</h2>
					<br>
					<ul>
						<li>each cgroup has its own perf_event</li>
						<ul>
							<li>needs (#events x #cpus x #cgroups) fds</li>
							<li>increases cgroup context switch overhead</li>
							<ul>
								<li>by reprogramming PMU counters</li>
							</ul>
						</ul>
						<li>workaround</li>
						<ul>
							<li>limits number of cgroups to profile at once</li>
							<li>creates blind spots and inconsistent data</li>
						</ul>
					</ul>
				</section>
				<section>
					<h2>Cgroup perf events</h2>
					<br>
					<ul>
						<li>cpu perf events with associated cgroup</li>
						<li>measuring same events across cgroups</li>
						<ul>
							<li>this is the most common use case at Google</li>
							<li>ensured by --for-each-cgroup</li>
						</ul>
						<li>no need to have separate events for cgroups</li>
						<ul>
							<li>but still need separate counts per cgroup</li>
						</ul>
					</ul>
				</section>
				<section>
					<h2>In-kernel aggregation</h2>
					<br>
					<ul>
						<li>proposed ioctl-based approach</li>
						<ul>
							<li>using a cpu event (for each cpu)</li>
							<li>collects event counts for current cgroup</li>
							<ul>
								<li>at context switch</li>
							</ul>
							<li>no PMU reprogramming during context switch</li>
						</ul>
						<li>rejected due to interface concerns</li>
						<ul>
							<li><a href="https://lore.kernel.org/lkml/20210413155337.644993-1-namhyung@kernel.org/">link to the discussion</a></li>
						</ul>
					</ul>
				</section>
				<section>
					<h2>BPF based approach</h2>
					<br>
					<ul>
						<li>thanks to bperf infra by Song Liu</li>
						<li>same design, but doing it in BPF</li>
						<ul>
							<li>attaches to cgroup-switches* event</li>
							<li>collects event counts for current cgroup</li>
							<li>saves the results in per-cpu array</li>
						</ul>
					</ul>
					<br>
					<br>
					* a software event added to v5.13
				</section>
				<section>
					<h2>Results</h2>
					<br>
					<ul>
						<li>estimated context switch time</li>
						<li>tasks communicate through pipes</li>
						<li>tasks are in different cgroups</li>
					</ul>
					<br>
					<br>
                                        <img src="img/bpf-cgrp-counter-intel.png" width="360">
                                        <img src="img/bpf-cgrp-counter-amd.png" width="360">
				</section>
				<section>
					<h2>Future</h2>
					<br>
					<ul>
						<li>triggers: start/stop perf events from bpf program</li>
						<li>Use bpf_get_branch_snapshot() in perf tools</li>
						<li>Helping developers figure out ENOSOMETHING from perf_event_open()</li>
						<li>As default case for evsel__open_strerror()</li>
						<li>Show a backtrace</li>
						<li>in addition to asking user to look at dmesg output</li>
						<li>Presentations at: http://vger.kernel.org/~acme/bpf/</li>
					</ul>
				</section>
			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
